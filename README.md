# Natural Language Processing

Using Natural Language Processing (NLP) in a nutshell is a technique that:

> Transforms text data and convert it to features that enable us to build models.

<p align="center">
<img src="https://github.com/marcotav/natural-language-processing/blob/master/neural-language-model-and-spinoza/images/Spinoza.jpg" width="350"/>   
</p> 


## Index

* [neural-language-model-and-spinoza](#neural-language-model-and-spinoza)


## neural-language-model-and-spinoza

In this project I built a language model for text generation using deep learning techniques. 

Though natural language, in principle, have formal structures and grammar, in practice it is full of ambiguities. Modeling it using examples and modeling is an interesting alternative. The definition of a (statistical) language model is:

> A statistical language model is a probability distribution over sequences of words. Given such a sequence it assigns a probability to the whole sequence.

The use of neural networks has become one of the main approaches to language modeling. Three properties can describe this neural language modeling (NLM) approach succinctly:

> We first associate words in the vocabulary with a distributed word feature vector, then express the joint probability function of word sequences in terms of the feature vectors of these words in the sequence and then learn simultaneously the word feature vector and the parameters of the probability function.

In this project I used Spinoza's Ethics (*Ethica, ordine geometrico demonstrata*) to build a NLM.
